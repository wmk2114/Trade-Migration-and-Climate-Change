---
title: '[SCRATCH] Replication MK'
author: "Wyatt King"
date: "2025-04-13"
output: html_document
---

```{r}
# Load required packages
library(haven)
library(dplyr)
library(readr)
library(stringr)
library(stargazer)

# Load data
mk_data <- read_dta("LDC_IO_replication.dta")
polity <- read_csv("Polity_Data.csv")

# === Step 1: Clean Polity country names ===
polity$country <- gsub(" ", "", polity$country)
polity$country <- gsub("\\(Burma\\)", "", polity$country)
polity$country <- gsub("Kyrgyzstan", "KyrgyzRepublic", polity$country)
colnames(polity)<- toupper(colnames(polity))
```

```{r}
get_rid_of_77<- function(x){
  if(is.na(x)){
    return(x)
  }
  else if(!is.numeric(x)){
    return(x)
  }
  else if(x<= -66){
    return(NA)
  }
  else{
    return(x)
  }
}

apply_function_to_dataframe <- function(df, func) {
  df[] <- lapply(df, function(col) {
    if(is.numeric(col)) {
      return(sapply(col, func))
    } else {
      return(col)
    }
  })
  return(df)
}

polity<-apply_function_to_dataframe(polity, get_rid_of_77)
```

```{r}
# === Step 2: Calculate custom Polity scores ===
calculate_new_polity_scores <- function(data) {
  data$DEMOC_NO_XCONST <- with(data, 
    ifelse(XRCOMP == 3, 2, ifelse(XRCOMP == 2, 1, 0)) +
    ifelse((XRCOMP %in% c(2, 3)) & (XROPEN %in% c(3, 4)), 1, 0) +
    ifelse(PARCOMP == 5, 3, 
           ifelse(PARCOMP == 4, 2, 
                  ifelse(PARCOMP == 3, 1, 0)))
  )

  data$AUTO_NO_XCONST <- with(data, 
    ifelse(XRCOMP == 1, 2, 0) +
    ifelse(XRCOMP == 1 & XROPEN %in% c(1, 2), 1, 0) +
    ifelse(PARREG == 4, 2, 
           ifelse(PARREG == 3, 1, 0)) +
    ifelse(PARCOMP == 1, 2, 
           ifelse(PARCOMP == 2, 1, 0))
  )

  data$POLITY_NO_XCONST <- data$DEMOC_NO_XCONST - data$AUTO_NO_XCONST
  return(data)
}

# Apply the score calculation
polity <- calculate_new_polity_scores(polity)
```

```{r}
# Make sure mk_data's country names are formatted similarly to polity$country
mk_data <- mk_data %>%
  mutate(
    merge_country = str_to_lower(str_trim(ctylabel)),
    merge_country = gsub(" ", "", merge_country)
  )

# Named vector for harmonization
harmonization_map <- c(
  "americansamoa" = "americansamoa",
  "antigua&barbuda" = "antiguaandbarbuda",
  "aruba" = "aruba",
  "bahamas" = "bahamas,the",
  "barbados" = "barbados",
  "belize" = "belize",
  "bermuda" = "bermuda",
  "brunei" = "brunei",
  "burkinafaso" = "burkinafaso",
  "capeverde" = "capeverde",
  "caymanislands" = "caymanislands",
  "centralafricanrepublic" = "centralafricanrepublic",
  "congo" = "congo",
  "costarica" = "costarica",
  "coted'ivoire" = "coted'ivoire",
  "czechrepublic" = "czechrepublic",
  "dominica" = "dominica",
  "dominicanrepublic" = "dominicanrepublic",
  "elsalvador" = "elsalvador",
  "equatorialguinea" = "equatorialguinea",
  "kyrgyzrepublic" = "kyrgyzrepublic"
)

# Apply harmonization
mk_data <- mk_data %>%
  mutate(merge_country = recode(merge_country, !!!harmonization_map),
         merge_year= date)

colnames(polity)<- tolower(colnames(polity))
polity_data <- polity %>%
  mutate(
    merge_country = str_to_lower(str_trim(country)),
    merge_year = year
  )

```

```{r}
lag_within_country <- function(df, var, new_var_name, lag_n = 1) {
  df <- df %>%
    group_by(country) %>%
    mutate(
      !!new_var_name := lag(get(var), n = lag_n, order_by = year)
    ) %>%
    ungroup()  # To remove the grouping after applying the lag
  
  return(df)
}

colnames(polity_data)
polity_data<-lag_within_country(df=polity_data, var="polity_no_xconst", new_var_name="l1_polity_no_xconst")
polity_data<-lag_within_country(df=polity_data, var="xconst", new_var_name="l1_xconst")
```


```{r}
merged_data <- mk_data %>%
  left_join(polity_data, by = c("merge_country", "merge_year"))
colnames(merged_data)
# Diagnostics
cat("Total MK observations:", nrow(mk_data), "\n")
cat("Matched with Polity:", sum(!is.na(merged_data$democ)), "\n")
```

```{r}
cor_test<- merged_data[is.na(merged_data$l1aclpn)==F & is.na(merged_data$l1_xconst)==F,]
cor(cor_test$l1aclpn, cor_test$l1_xconst)
```


```{r}
merged_data$aclpn2<- as.factor(merged_data$aclpn)
```

```{r}
mc_1<- c("l1_xconst", "l1aclpn", "l1_polity_no_xconst", "l1lnpop", "l1gdp_pc", "newtar", "date", "ctylabel")

mdf_1<- na.omit(merged_data[mc_1])
mdf_1$l1aclpn<- as.factor(mdf_1$l1aclpn)

mm1_1<- prais::prais_winsten(newtar~l1_xconst*l1aclpn+l1_polity_no_xconst+l1lnpop+l1gdp_pc+date+as.factor(ctylabel), data=mdf_1, index=c("date", "ctylabel"))
sum_mm1<-summary(mm1_1)
```

```{r}
mc_2<- c("l1_xconst", "l1aclpn", "l1lnpop", "l1gdp_pc", "l1ecris2", "l1bpc1", "l1signed", "l1office", "l1avnewtar", "l1gatt_wto_new", "l1fdi", "newtar", "date", "ctylabel")
mdf_2<- na.omit(merged_data[mc_2])
```

```{r}
mm2<- prais::prais_winsten(newtar~.+l1_xconst:l1aclpn, data=mdf_2, index = c("date", "ctylabel"))
sum_mm2<-summary(mm2)
```

```{r}
mc_3<- c("l1_xconst", "l1_polity_no_xconst", "l1lnpop", "l1gdp_pc", "newtar", "date", "ctylabel")

mdf_3<- na.omit(merged_data[mc_3])
mdf_3$l1aclpn<- as.factor(mdf_1$l1aclpn)

mm3<- prais::prais_winsten(newtar~l1_xconst*l1_polity_no_xconst+l1lnpop+l1gdp_pc+date+as.factor(ctylabel), data=mdf_3, index=c("date", "ctylabel"))
sum_mm3<-summary(mm3)
```

```{r}
stargazer(sum_mm1, sum_mm2, sum_mm3)
```

```{r}
convert_dict<- function(x){
  if(is.na(x)){
    return(NA)
  }
  else if(x==8){
    return(4)
  }
  else if(x==6 | x==1){
    return(3)
  }
  else if(x==4){
    return(2)
  }
  else if(x==2){
    return(0)
  }
  else{
    return(1)
  }
}


merged_data$l1dictator1_2<- sapply(merged_data$l1dictator1, convert_dict)
```
```







```{r}
calculate_polity_scores <- function(data) {
  # Democracy Score
  data$DEMOC <- with(data, 
    ifelse(XRCOMP == 3, 2, ifelse(XRCOMP == 2, 1, 0)) +
    ifelse((XRCOMP %in% c(2, 3)) & (XROPEN %in% c(3, 4)), 1, 0) +
    ifelse(XCONST == 7, 4, 
           ifelse(XCONST == 6, 3, 
                  ifelse(XCONST == 5, 2, 
                         ifelse(XCONST == 4, 1, 0)))) +
    ifelse(PARCOMP == 5, 3, 
           ifelse(PARCOMP == 4, 2, 
                  ifelse(PARCOMP == 3, 1, 0)))
  )

  # Autocracy Score
  data$AUTOC <- with(data, 
    ifelse(XRCOMP == 1, 2, 0) +
    ifelse(XRCOMP == 1 & XROPEN %in% c(1, 2), 1, 0) +
    ifelse(XCONST == 1, 3, 
           ifelse(XCONST == 2, 2, 
                  ifelse(XCONST == 3, 1, 0))) +
    ifelse(PARREG == 4, 2, 
           ifelse(PARREG == 3, 1, 0)) +
    ifelse(PARCOMP == 1, 2, 
           ifelse(PARCOMP == 2, 1, 0))
  )

  # Combined Polity Score
  data$POLITY <- data$DEMOC - data$AUTOC

  return(data)
}
```



```{r}
library(haven)       # to read Stata files (.dta)
library(dplyr) # for data wrangling
library(plm)         # for panel data regression
library(lmtest)      # for coeftest()
library(sandwich) 
library(stargazer)
```

```{r}
data<- haven::read_dta("/Users/wyatttheking/Desktop/Spring 2025/TMCC/Research Project/Replication Data/LDC_IO_replication.dta")
data$country<-as.factor(data$country)
```

```{r}
pdata <- pdata.frame(data, index = c("country", "date"))
```

```{r}
model <- plm(newtar ~ l1polity + l1lnpop + l1gdp_pc + country, 
             data = pdata, 
             model = "within")

coeftest(model, vcov = vcovHC(model, type = "HC1", cluster = "group"))
```

```{r}
colnames(data)
```

### OLS Models
Lagged by one, remove columns with NA
```{r}
sort(colnames(data))
# We include our variables for our first model
l1_data<- data[colnames(data) %in% c("newtar", "polityiv_update2", "gdp_pc_95d", "lnpop", "date", "country")]
```

```{r}
# We remove NA values from our data
l1_data_clean<- na.omit(l1_data)
dim(l1_data_clean)
length(unique(l1_data_clean$country))
```

```{r}
m1<- lm(newtar~., data=l1_data_clean)
pw<- prais::prais_winsten(m1, data=l1_data_clean, index=c("country", "date"))
summary(pw)

?prais_winsten
```

```{r}
data <- data[order(data$country, data$date), ]

m1<- lm(avnewtar~l1polity+l1gdp_pc+l1lnpop+date+country, data=data)
pw<- prais::prais_winsten(m1, data=data, index=c("country", "date"))

data

?prais_winsten

lmtest::coeftest(m1, vcov. = NULL, type = "HC1")
coeftest

car::durbinWatsonTest(m1)
```

# ChatGPT Results
```{r}
# Load necessary libraries
library(haven)       # To read Stata files
library(dplyr)       # For data manipulation
library(plm)         # For panel data models
library(lmtest)      # For robust standard errors
library(sandwich)    # Robust covariance matrix
library(stargazer)   # For model output

# Load your dataset
data <- read_dta("your_data.dta")  # replace with actual .dta file name

# Convert to pdata.frame for panel data structure
data <- pdata.frame(data, index = c("country", "date"))

# Generate lagged variables
data <- data %>%
  mutate(
    l1polity = lag(polity, 1),
    l1lnpop = lag(lnpop, 1),
    l1gdp_pc = lag(gdp_pc_95d, 1),
    l1ecris2 = lag(ecris2, 1),
    l1bpc1 = lag(bpc1, 1),
    l1signed = lag(signed, 1),
    l1usheg = lag(usheg, 1),
    l1fiveop = lag(fiveop, 1),
    l1avnewtar = lag(avnewtar, 1),
    l1office = lag(yrsoffic, 1),
    l1gatt_wto_new = lag(gatt_wto_new, 1),
    l1fdi = lag(fdignp, 1),
    l1aclpn = lag(aclpn, 1)
  )

# Run regressions (models m21 to m26 as examples
m21 <- plm(newtar ~ l1polity + l1lnpop + l1gdp_pc + country +as.numeric(date), data = pdata, model = "within", index = c("country", "time"))
summary(m21)
colnames(data)

m21 <- plm(newtar ~ l1polity + l1lnpop + l1gdp_pc + factor(country)+ as.numeric(date), data = data, model = "within", index = c("country", "time"))

data_gls <- as.data.frame(data)
data_gls$country <- droplevels(as.factor(data_gls$country))

m22 <- plm(newtar ~ l1polity + l1lnpop + l1gdp_pc + l1ecris2 + factor(country)+as.numeric(date), data = data, model = "within")
summary(m22)
m23 <- plm(newtar ~ l1polity + l1lnpop + l1gdp_pc + l1bpc1 + factor(country), data = data, model = "within")
m24 <- plm(newtar ~ l1polity + l1lnpop + l1gdp_pc + l1signed + factor(country), data = data, model = "within")
m25 <- plm(newtar ~ l1polity + l1lnpop + l1gdp_pc + l1usheg + factor(country), data = data, model = "within")
m26 <- plm(newtar ~ l1polity + l1lnpop + l1gdp_pc + l1fiveop + factor(country), data = data, model = "within")

# Export results (similar to estout)
stargazer(m21, m22, m23, m24, m25, m26, type = "text", out = "t2.txt",
          title = "Table 2. Dependent Variable: Statutory Tariff Rates",
          column.labels = c("M21", "M22", "M23", "M24", "M25", "M26"),
          covariate.labels = c("POLITY", "LN POP", "GDP PC", "EC CRISIS", "BP CRISIS", "IMF", "US HEG", "FIVE OPEN", "Constant"),
          dep.var.labels = "Statutory Tariff Rate",
          keep.stat = c("n", "rsq", "f"))
```



```{r}
# Table 3 models
m31 <- plm(newtar ~ l1polity + l1lnpop + l1gdp_pc + l1ecris2 + l1bpc1 + l1signed + l1avnewtar + l1office + factor(country)+as.numeric(date), data = data, model = "within")
summary(m31)
m32 <- plm(newtar ~ l1polity + l1lnpop + l1gdp_pc + l1ecris2 + l1bpc1 + l1signed + l1office + l1gatt_wto_new + l1fiveop + l1usheg + factor(country), data = data, model = "within")
m33 <- plm(newtar ~ l1polity + l1lnpop + l1gdp_pc + l1ecris2 + l1bpc1 + l1signed + l1office + l1avnewtar + l1gatt_wto_new + l1fdi + factor(country), data = data, model = "within")
m34 <- plm(newtar ~ l1aclpn + l1lnpop + l1gdp_pc + l1ecris2 + l1bpc1 + l1signed + l1office + l1avnewtar + l1gatt_wto_new + l1fdi + factor(country), data = data, model = "within")

# Export Table 2 results
stargazer(m21, m22, m23, m24, m25, m26, type = "text", out = "t2.txt",
          title = "Table 2. Dependent Variable: Statutory Tariff Rates",
          column.labels = c("M21", "M22", "M23", "M24", "M25", "M26"),
          covariate.labels = c("POLITY", "LN POP", "GDP PC", "EC CRISIS", "BP CRISIS", "IMF", "US HEG", "FIVE OPEN", "Constant"),
          dep.var.labels = "Statutory Tariff Rate",
          keep.stat = c("n", "rsq", "f"))

# Export Table 3 results
stargazer(m31, m32, m33, m34, type = "text", out = "t3.txt",
          title = "Table 3. Extended Tariff Rate Models",
          column.labels = c("M31", "M32", "M33", "M34"),
          dep.var.labels = "Statutory Tariff Rate",
          keep.stat = c("n", "rsq", "f"))
```
